# Load-local-LLMs
Choose a model you like from: https://ollama.com/search

deepseek-r1 as an example: 

download command: 
<pre> ollama pull deepseek-r1 </pre>

run command: 
<pre> ollama run deepseek-r1  </pre>

Then you can ask questions and get responses. 
